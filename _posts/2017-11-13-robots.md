---
layout: blog_post
title:  "Robots.txt"
meta: "What is robots.txt and how do you configure it"
date:   2017-11-13 12:11:21 +0100
comments: true 
categories: jekyll update
---
# What is Robots.txt
Robots.txt helps you optimize your site for search engines like Google or web-robots trying to collect information about your site. Any search robot visiting your site will first check your sites robots.txt file to see what pages not to visit. 

{% highlight txt%}
//Robots.txt
User-agent: *
Disallow: /
{% endhighlight%}
User-agent: specefies which bots should read this. If you User-agent: is followed by a * means this applies to all robots visiting this site. Disallow: / tells the robot to not visit any page. Disallow:/private/ tells the robots not to visit any part of the private section.
{% highlight txt%}
//Robots.txt
User-agent: Google
Disallow:

User-agent: *
Disallow: /
{% endhighlight%}
You can also customize and and allow specific robots complete access and and and block the rest.

Robots can ignore your robots.txt file if the wish to, the file only tells robot what they "shouldn't" look at but cant stop them. Often will malware robots just ignore the robots.txt file. And since the robots.txt file is public any user can see what parts of you site you are trying to hide. 

